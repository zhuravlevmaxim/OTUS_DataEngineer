{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark context started\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('twitter-sentiment').getOrCreate()\n",
    "spark.sparkContext.addPyFile(\"/home/jovyan/work/sentiment_model.py\")\n",
    "print(\"Spark context started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+\n",
      "|target| count|\n",
      "+------+------+\n",
      "|     1|800000|\n",
      "|     0|800000|\n",
      "+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, LongType, StringType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"target\", IntegerType(), True),\n",
    "    StructField(\"id\", LongType(), True),\n",
    "    StructField(\"raw_timestamp\", StringType(), True),\n",
    "    StructField(\"query_status\", StringType(), True),\n",
    "    StructField(\"author\", StringType(), True),\n",
    "    StructField(\"tweet\", StringType(), True)\n",
    "])\n",
    "    \n",
    "data_path = \"/home/jovyan/data/training.1600000.processed.noemoticon.csv\"\n",
    "\n",
    "raw_sentiment = spark.read.csv(data_path,header=False,schema=schema) \\\n",
    "    .selectExpr(\"(case when target=4 then 1 else 0 end) as target\",\"tweet\")\n",
    "\n",
    "\n",
    "\n",
    "raw_sentiment.groupBy(\"target\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<function pre...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "def read_model(model_path):\n",
    "    with open(model_path,'rb') as buffer:\n",
    "        return pkl.load(buffer)\n",
    "\n",
    "model_path = \"/home/jovyan/tweet_sentiment.mdl\"\n",
    "\n",
    "model_object = read_model(model_path)\n",
    "model_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/spark/python/pyspark/sql/session.py:366: UserWarning: Using RDD of dict to inferSchema is deprecated. Use pyspark.sql.Row instead\n",
      "  warnings.warn(\"Using RDD of dict to inferSchema is deprecated. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+--------------------+\n",
      "|       proba|target|                text|\n",
      "+------------+------+--------------------+\n",
      "|0.5134324485|     0|@switchfoot http:...|\n",
      "|0.4883034084|     0|is upset that he ...|\n",
      "| 0.479001187|     0|@Kenichan I dived...|\n",
      "| 0.468310149|     0|my whole body fee...|\n",
      "|0.4856440795|     0|@nationwideclass ...|\n",
      "|0.4959264044|     0|@Kwesidei not the...|\n",
      "|0.4829489093|     0|         Need a hug |\n",
      "|0.4968608392|     0|@LOLTrish hey  lo...|\n",
      "|0.4830092384|     0|@Tatiana_K nope t...|\n",
      "|0.4959264044|     0|@twittera que me ...|\n",
      "|0.5010254401|     0|spring break in p...|\n",
      "|0.4959264044|     0|I just re-pierced...|\n",
      "|0.4900247464|     0|@caregiving I cou...|\n",
      "|0.4686489648|     0|@octolinz16 It it...|\n",
      "|0.4703860344|     0|@smarrison i woul...|\n",
      "|0.4789244884|     0|@iamjazzyfizzle I...|\n",
      "|0.4597403691|     0|Hollis' death sce...|\n",
      "|0.4977367909|     0|about to file taxes |\n",
      "|0.4983091373|     0|@LettyA ahh ive a...|\n",
      "|0.4944417277|     0|@FakerPattyPattz ...|\n",
      "+------------+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_object_broadcast = spark.sparkContext.broadcast(model_object)\n",
    "\n",
    "def block_iterator(iterator, size):\n",
    "    bucket = list()\n",
    "    for e in iterator:\n",
    "        bucket.append(e)\n",
    "        if len(bucket) >= size:\n",
    "            yield bucket\n",
    "            bucket = list()\n",
    "    if bucket:\n",
    "        yield bucket\n",
    "\n",
    "def block_classify(iterator):\n",
    "    model = model_object_broadcast.value\n",
    "    for features in block_iterator(iterator, 10000):\n",
    "        import pandas as pd\n",
    "        import json\n",
    "        features_df = pd.DataFrame(list(features), columns=[\"target\",\"text\"])\n",
    "        pred = model.predict_proba(features_df[\"text\"])\n",
    "        res_df = features_df\n",
    "        res_df[\"proba\"] = pred[:,1]\n",
    "        for e in json.loads(res_df.to_json(orient='records')):\n",
    "            yield e\n",
    "\n",
    "predicted_df = raw_sentiment.rdd.mapPartitions(block_classify).toDF()\n",
    "\n",
    "predicted_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
